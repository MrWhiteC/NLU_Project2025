{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb04d7d-185b-4727-a2dd-a6ca5b302ed4",
   "metadata": {},
   "source": [
    "# Import Library and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c11426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch, torchtext\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random, math, time\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f36479-9960-4e36-94ec-0c77981bbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu121 0.16.2+cpu 4.39.3\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import torch, torchtext, transformers\n",
    "import numpy\n",
    "print(torch.__version__, torchtext.__version__, transformers.__version__)\n",
    "print(numpy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6571c42-71df-4995-bb2a-5a735ccb0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the dataset from disk\n",
    "loaded_dataset = load_from_disk('dataset_edit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fa862a-c2ab-47db-ac2f-6493ceb76f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loaded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04db58a-0b78-479e-8e3d-0aec39244754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'entity', 'label'],\n",
       "        num_rows: 452057\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text1', 'entity', 'label'],\n",
       "        num_rows: 83926\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text1', 'entity', 'label'],\n",
       "        num_rows: 153206\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d6a048-c97d-4055-981c-1680a39cd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].rename_column(\"label\", \"labels\")\n",
    "dataset[\"validation\"] = dataset[\"validation\"].rename_column(\"label\", \"labels\")\n",
    "dataset[\"test\"] = dataset[\"test\"].rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad1c155-2a3f-45a5-9cc2-d81e90bd35be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'entity', 'labels'],\n",
       "        num_rows: 452057\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text1', 'entity', 'labels'],\n",
       "        num_rows: 83926\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text1', 'entity', 'labels'],\n",
       "        num_rows: 153206\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f33186-6747-47a6-8a83-ffc7184212e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classModel import ContextBertModel, QACGBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59441625-f514-4fd6-be44-e0cdd82b8cd1",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4752789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# from transformers import BertTokenizer\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('ibm-research/CTI-BERT')\n",
    "\n",
    "# # Function to tokenize the text data\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['text1'], padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "# # Apply tokenization to train and validation datasets\n",
    "# train_data = dataset['train'].map(tokenize_function, batched=True)\n",
    "# val_data = dataset['validation'].map(tokenize_function, batched=True)\n",
    "# test_data = dataset['test'].map(tokenize_function, batched=True)\n",
    "\n",
    "# # Print an example to verify\n",
    "# print(train_data[0]['text1'])  # It should show tokenized input\n",
    "\n",
    "# # # Decode the tokenized text back to human-readable text\n",
    "# # decoded_text = tokenizer.decode(train_data[0]['input_ids'], skip_special_tokens=True)\n",
    "# # print(f\"Decoded Text: {decoded_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3efd4026-cf20-48f4-98dc-8e2adaa18a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save each split to disk\n",
    "# train_data.save_to_disk(\"tokenized_data_edit/train\")\n",
    "# val_data.save_to_disk(\"tokenized_data_edit/validation\")\n",
    "# test_data.save_to_disk(\"tokenized_data_edit/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cc07e1c-8a34-4c91-beb0-1349b64e535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "# .select(range(10000))\n",
    "train_data = load_from_disk(\"tokenized_data_edit/train\")\n",
    "val_data = load_from_disk(\"tokenized_data_edit/validation\")\n",
    "test_data = load_from_disk(\"tokenized_data_edit/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "617249f8-95d7-424c-9907-1f159afee61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "val_data = val_data.rename_column(\"label\", \"labels\")\n",
    "test_data = test_data.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac0633e8-36b7-43bd-b520-3f2bf36ac504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text1', 'entity', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 452057\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437e99e-f2f3-43a8-96ac-6e0a6c64639f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d97137d6-9489-4ecb-a4f7-b0d4f9ff6522",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f205f2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fbb4de91e94ecda005f78d623d5dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/452057 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6002864cb94f50a90993b66d5606a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83926 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text1': 'These Microsoft Office templates are hosted on a command and control server and the downloaded link is embedded in the first stage malicious document', 'entity': 'I-TOOL', 'labels': 290, 'input_ids': [2, 455, 755, 1899, 8818, 226, 4700, 158, 43, 979, 137, 656, 629, 137, 114, 3633, 695, 146, 3718, 120, 114, 773, 3872, 815, 1355, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels (MITRE techniques) from both train and validation datasets\n",
    "labels = list(set(dataset['train']['labels']).union(set(dataset['validation']['labels'])))  # Extract unique labels\n",
    "label_map = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Function to encode labels into integers\n",
    "def encode_labels(examples):\n",
    "    # Safely map the labels, providing a default value if a label is not found in the label_map\n",
    "    examples['labels'] = [label_map.get(label, -1) for label in examples['labels']]\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Apply label encoding\n",
    "train_data = train_data.map(encode_labels, batched=True)\n",
    "val_data = val_data.map(encode_labels, batched=True)\n",
    "\n",
    "# Print an example to verify\n",
    "print(train_data[3])  # It should show tokenized input along with the encoded label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7b46f6-7091-438a-9220-c256ec00e629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1113\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][5]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d948d17f-308d-48d9-b49b-4a9702c64c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57df874f209c40b39333d1189a487096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/452057 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd3c3c672b14ccba3980c4be2502d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/83926 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text1': 'These Microsoft Office templates are hosted on a command and control server and the downloaded link is embedded in the first stage malicious document', 'entity': 'I-TOOL', 'labels': 290, 'input_ids': [2, 455, 755, 1899, 8818, 226, 4700, 158, 43, 979, 137, 656, 629, 137, 114, 3633, 695, 146, 3718, 120, 114, 773, 3872, 815, 1355, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'context_ids': [15]}\n"
     ]
    }
   ],
   "source": [
    "# Make sure each 'entity' is treated as a full string, not split into characters\n",
    "unique_aspects = list(set(aspects for aspects in dataset['train']['entity']))\n",
    "context_map = {asp: i+1 for i, asp in enumerate(unique_aspects)}  # +1 to reserve 0 for padding\n",
    "\n",
    "# Update encoding accordingly\n",
    "def encode_context(examples):\n",
    "    examples[\"context_ids\"] = [\n",
    "        [context_map[a] for a in aspects if a in context_map] if isinstance(aspects, list) else [context_map.get(aspects, 0)]\n",
    "        for aspects in examples[\"entity\"]\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "# Apply context encoding\n",
    "train_data = train_data.map(encode_context, batched=True)\n",
    "val_data = val_data.map(encode_context, batched=True)\n",
    "\n",
    "# Print an example to verify\n",
    "print(train_data[3])  # It should show tokenized input along with the encoded label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c4556b9-90c1-46c7-8c56-32a38146ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_id = max(max(x[\"context_ids\"]) for x in train_data)\n",
    "# print(\"ðŸ” Max context ID:\", max_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81a52182-5e20-4500-9520-b0aed6f991d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_context_id = 0\n",
    "# for i in range(len(train_data)):\n",
    "#     ids = train_data[i][\"context_ids\"]\n",
    "#     max_context_id = max(max_context_id, max(ids))\n",
    "\n",
    "# print(\"ðŸš¨ Max context_id in dataset:\", max_context_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7e517b2-524d-400f-9411-7cfef44bd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"âœ… context_embeddings size:\", model.bert.context_embeddings.num_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46472511-7c2c-4a11-8876-82951de03ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TTPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, label_key='labels', max_context_id=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.label_key = label_key\n",
    "        self.max_context_id = max_context_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        context_ids = torch.tensor(item[\"context_ids\"], dtype=torch.long)\n",
    "\n",
    "        if self.max_context_id is not None:\n",
    "            context_ids = torch.clamp(context_ids, min=0, max=self.max_context_id)\n",
    "\n",
    "        label = item[self.label_key]\n",
    "        if label == -1:\n",
    "            # Replace -1 with a default class, like 0\n",
    "            label = 0  # or skip the example entirely\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(item[\"input_ids\"]),\n",
    "            \"token_type_ids\": torch.tensor(item[\"token_type_ids\"]),\n",
    "            \"attention_mask\": torch.tensor(item[\"attention_mask\"]),\n",
    "            \"labels\": torch.tensor(item[self.label_key]),\n",
    "            \"context_ids\": context_ids\n",
    "        }\n",
    "\n",
    "train_dataset = TTPDataset(train_data)\n",
    "val_dataset = TTPDataset(val_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ce37b-4535-432c-bd42-0fdee4eab208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1928357b-3d78-4827-bc14-5f845f60f399",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3910bb78-0cc4-4a11-b19e-ffef21f4ff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124945/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QACGBertForSequenceClassification(\n",
       "  (bert): ContextBertModel(\n",
       "    (embeddings): BERTEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BERTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ContextBERTEncoder(\n",
       "      (context_layer): ModuleList(\n",
       "        (0-11): 12 x Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ContextBERTLayer(\n",
       "          (attention): ContextBERTAttention(\n",
       "            (self): ContextBERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): ContextBERTPooler(\n",
       "      (attention_gate): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (context_embeddings): Embedding(34, 768)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=505, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from classModel import QACGBertForSequenceClassification\n",
    "from transformers import BertConfig  # â† this is the correct one\n",
    "\n",
    "max_context_id = 33\n",
    "config = BertConfig.from_pretrained(\n",
    "    \"ibm-research/CTI-BERT\",\n",
    "    num_labels=len(labels), # This is allowed now\n",
    "    num_context_ids=max_context_id + 1\n",
    ")\n",
    "\n",
    "# Add any other custom fields you need\n",
    "config.context_dim = 68  # if required for your model\n",
    "config.num_context_ids = 34 \n",
    "\n",
    "model = QACGBertForSequenceClassification(config, num_labels=len(labels))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d3100-48ee-47b5-a41c-2fb9b41d62b7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "768f10eb-bf95-43ee-93de-358ddc6c027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Training Loss   Validation Loss   Accuracy  Precision  Recall   F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     No log          4.768497          0.102328  0.074183   0.102328 0.072063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     2.398145        4.694597          0.148178  0.131304   0.148178 0.117844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     1.706076        4.723936          0.168077  0.163138   0.168077 0.144451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     1.323521        4.756011          0.175047  0.178341   0.175047 0.153007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     1.081894        4.769297          0.190084  0.192082   0.190084 0.168840\n"
     ]
    }
   ],
   "source": [
    "# use this\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    # preds = preds.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "print(f\"{'Epoch':<6}{'Training Loss':<16}{'Validation Loss':<18}{'Accuracy':<10}{'Precision':<11}{'Recall':<9}{'F1'}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        context_ids = batch[\"context_ids\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            seq_lens=[input_ids.size(1)] * input_ids.size(0),\n",
    "            context_ids=context_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss, logits = outputs[:2]\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    val_total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            context_ids = batch[\"context_ids\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                seq_lens=[input_ids.size(1)] * input_ids.size(0),\n",
    "                context_ids=context_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss, logits = outputs[:2]\n",
    "            val_total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss = val_total_loss / len(val_loader)\n",
    "    metrics = compute_metrics(preds=np.array(all_preds), labels=np.array(all_labels))\n",
    "\n",
    "    # print(f\"{epoch+1:<6}{epoch_train_loss if epoch > 0 else 'No log':<16.6f}{val_loss:<18.6f}\"\n",
    "    #       f\"{metrics['accuracy']:<10.6f}{metrics['precision']:<11.6f}\"\n",
    "    #       f\"{metrics['recall']:<9.6f}{metrics['f1']:.6f}\")\n",
    "    train_loss_str = f\"{epoch_train_loss:.6f}\" if epoch > 0 else \"No log\"\n",
    "    print(f\"{epoch+1:<6}{train_loss_str:<16}{val_loss:<18.6f}\"\n",
    "          f\"{metrics['accuracy']:<10.6f}{metrics['precision']:<11.6f}\"\n",
    "          f\"{metrics['recall']:<9.6f}{metrics['f1']:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526ab31-75e0-4db6-8632-f3022087623c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83cc36-c47b-46ae-9dcb-7b309e457951",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model/full_model_edit.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbed29e9-a44d-4448-9c99-d2d937a493b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model/full_model.pth')\n",
    "# model.to(device)\n",
    "# model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38e9c1-1b5c-45fc-8e1a-7a735c1ed13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85838fc-5339-47e6-8c47-4d286c660f68",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43356af6-b223-46ab-86fd-dc62ef47c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st124945/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy NER model (make sure to download the model if not already installed)\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # or any other model you are using\n",
    "\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ibm-research/CTI-BERT\")\n",
    "model = torch.load(\"model/full_model_edit.pth\", map_location=device)\n",
    "model.eval()\n",
    "\n",
    "# Make sure `labels` and `context_map` are accessible\n",
    "# If needed, regenerate from training data\n",
    "labels = list(label_map.keys())\n",
    "labels.sort(key=lambda x: label_map[x])  # Ensure label order matches model output\n",
    "\n",
    "# Prediction function\n",
    "def predict_single(text):\n",
    "    # Run NER to extract context entities using spaCy\n",
    "    doc = nlp(text)  # 'doc' is a spaCy document object\n",
    "    aspects = list(set([ent.label_ for ent in doc.ents]))  # Extract the NER labels\n",
    "    \n",
    "    # Convert context to context_ids\n",
    "    context_ids = [context_map.get(a, 0) for a in aspects]\n",
    "    context_ids = torch.tensor([context_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    # Tokenize input text using the tokenizer\n",
    "    encoded = tokenizer(text, padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    token_type_ids = encoded['token_type_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "    # Sequence length\n",
    "    seq_lens = [input_ids.size(1)]\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            seq_lens=seq_lens,\n",
    "            context_ids=context_ids\n",
    "        )\n",
    "        logits = outputs\n",
    "        probs = F.softmax(logits, dim=1).squeeze()\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        pred_label = labels[pred_idx]\n",
    "\n",
    "    return pred_label, probs.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c546f538-7534-4544-9fb8-5236b23dff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the prediction\n",
    "# input_text = input(\"Enter text to classify: \")\n",
    "# predicted_label, prob_scores = predict_single(input_text)\n",
    "\n",
    "# print(f\"\\nPredicted Label: {predicted_label}\")\n",
    "# print(\"Confidence Scores:\")\n",
    "# for i, label in enumerate(labels):\n",
    "#     print(f\"{label}: {prob_scores[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1094fea-55eb-4647-b327-f25b7be39557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "import spacy\n",
    "\n",
    "# Load tokenizer and spaCy model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ibm-research/CTI-BERT\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Inverse label map\n",
    "label_map_rev = {v: k for k, v in label_map.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f26f0063-cf33-4ec5-902a-6a598dee35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(text, model, tokenizer, context_map, label_map_rev, device, max_len=64):\n",
    "    # 1. Tokenize input\n",
    "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
    "\n",
    "    seq_len = input_ids.size(1)\n",
    "\n",
    "    # 2. Extract entities using spaCy for context\n",
    "    doc = nlp(text)\n",
    "    aspects = list(set([ent.text for ent in doc.ents if ent.text in context_map]))\n",
    "\n",
    "\n",
    "    # 3. Encode context\n",
    "    context_ids = [context_map.get(a, 0) for a in aspects]\n",
    "    if not context_ids:\n",
    "        context_ids = [0]  # default to padding if no valid entity\n",
    "    context_ids = torch.tensor([context_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    # 4. Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            seq_lens=[seq_len],\n",
    "            context_ids=context_ids,\n",
    "        )\n",
    "\n",
    "    logits = outputs\n",
    "    probs = F.softmax(logits, dim=1).squeeze()\n",
    "    pred_idx = torch.argmax(probs).item()\n",
    "    pred_label = label_map_rev[pred_idx]\n",
    "\n",
    "    return pred_label, probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb7b22b0-add5-40d6-89bf-60fc15335215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify:  An Iranian state-sponsored actor has been observed scanning and attempting to abuse the Log4Shell flaw in publicly-exposed Java applications to deploy a hitherto undocumented PowerShell-based modular backdoor dubbed \"CharmPower\" for follow-on post-exploitation.  \"The actor's attack setup was obviously rushed, as they used the basic open-source tool for the exploitation and based their operations on previous infrastructure, which made the attack easier to detect and attribute,\" researchers from Check Point said in a report published this week.  The Israeli cybersecurity company linked the attack to a group known as APT35, which is also tracked using the codenames Charming Kitten, Phosphorus, and TA453, citing overlaps with toolsets previously identified as infrastructure used by the threat actor.  Cybersecurity Log4Shell aka CVE-2021-44228 (CVSS score: 10.0) concerns a critical security vulnerability in the popular Log4j logging library that, if successfully exploited, could lead to remote execution of arbitrary code on compromised systems.  The ease of the exploitation coupled with the widespread use of Log4j library has created a vast pool of targets, even as the shortcoming has attracted swarms of bad actors, who have seized on the opportunity to stage a dizzying array of attacks since its public disclosure last month.  While Microsoft previously pointed out APT35's efforts to acquire and modify the Log4j exploit, the latest findings show that the hacking group has operationalized the flaw to distribute the PowerShell implant capable of retrieving next-stage modules and exfiltrating data to a command-and-control (C2) server.  Log4j Vulnerability CharmPower's modules also support a variety of intelligence gathering functionality, including features to gather system information, list installed applications, take screenshots, enumerate running processes, execute commands sent from the C2 server, and clean up any signs of evidence created by these components.  Cybersecurity The disclosure comes as Microsoft and the NHS cautioned that internet-facing systems running VMware Horizon are being targeted to deploy web shells and a new strain of ransomware called NightSky, with the tech giant connecting the latter to a China-based operator dubbed DEV-0401, which has also deployed LockFile, AtomSilo, and Rook ransomware in the past.  What's more, Hafnium, another threat actor group operating out of China, has also been observed utilizing the vulnerability to attack virtualization infrastructure to extend their typical targeting, Microsoft noted.  \"Judging by their ability to take advantage of the Log4j vulnerability and by the code pieces of the CharmPower backdoor, the actors are able to change gears rapidly and actively develop different implementations for each stage of their attacks,\" the researchers said.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Label: T1098.003\n",
      "\n",
      "Top 5 Confidence Scores:\n",
      "T1098.003: 0.0329\n",
      "T1569.001: 0.0271\n",
      "T1027.008: 0.0257\n",
      "T1218.011: 0.0231\n",
      "T1129: 0.0180\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_text = input(\"Enter text to classify: \")\n",
    "predicted_label, confidence_scores = predict_single(input_text, model, tokenizer, context_map, label_map_rev, device)\n",
    "\n",
    "print(f\"\\nPredicted Label: {predicted_label}\")\n",
    "print(\"\\nTop 5 Confidence Scores:\")\n",
    "\n",
    "# Get indices of top 5 scores\n",
    "top_indices = np.argsort(confidence_scores)[-5:][::-1]\n",
    "\n",
    "for idx in top_indices:\n",
    "    label = label_map_rev[idx]\n",
    "    score = confidence_scores[idx]\n",
    "    print(f\"{label}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "123c83b3-191b-43c6-bca1-071dcdb4510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_single(text, model, tokenizer, context_map, label_map_rev, device, max_len=64):\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Split the input text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    sentence_predictions = []\n",
    "\n",
    "    # 2. Process each sentence separately\n",
    "    for sentence in sentences:\n",
    "        # 2.1 Tokenize input\n",
    "        inputs = tokenizer(sentence, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
    "\n",
    "        seq_len = input_ids.size(1)\n",
    "\n",
    "        # 2.2 Extract entities using spaCy for context\n",
    "        doc = nlp(sentence)\n",
    "        aspects = list(set([ent.text for ent in doc.ents if ent.text in context_map]))\n",
    "\n",
    "        # 2.3 Encode context\n",
    "        context_ids = [context_map.get(a, 0) for a in aspects]\n",
    "        if not context_ids:\n",
    "            context_ids = [0]  # default to padding if no valid entity\n",
    "        context_ids = torch.tensor([context_ids], dtype=torch.long).to(device)\n",
    "\n",
    "        # 2.4 Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                seq_lens=[seq_len],\n",
    "                context_ids=context_ids,\n",
    "            )\n",
    "\n",
    "        logits = outputs\n",
    "        probs = F.softmax(logits, dim=1).squeeze()\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        pred_label = label_map_rev[pred_idx]\n",
    "        \n",
    "        # Convert confidence scores to percentage\n",
    "        probs_percent = probs.cpu().numpy() * 100  # Multiply by 100 to convert to percentage\n",
    "\n",
    "        # Format the probabilities as percentages for clarity\n",
    "        probs_percent_formatted = [f\"{prob:.2f}%\" for prob in probs_percent]\n",
    "\n",
    "        sentence_predictions.append((sentence, pred_label, probs_percent_formatted))\n",
    "\n",
    "    # Return the list of sentence predictions (each sentence, its label, and confidence scores as percentages)\n",
    "    return sentence_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97152427-450a-4596-b717-96c4f3df5822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter text to classify:   An Iranian state-sponsored actor has been observed scanning and attempting to abuse the Log4Shell flaw in publicly-exposed Java applications to deploy a hitherto undocumented PowerShell-based modular backdoor dubbed \"CharmPower\" for follow-on post-exploitation.  \"The actor's attack setup was obviously rushed, as they used the basic open-source tool for the exploitation and based their operations on previous infrastructure, which made the attack easier to detect and attribute,\" researchers from Check Point said in a report published this week.  The Israeli cybersecurity company linked the attack to a group known as APT35, which is also tracked using the codenames Charming Kitten, Phosphorus, and TA453, citing overlaps with toolsets previously identified as infrastructure used by the threat actor.  Cybersecurity Log4Shell aka CVE-2021-44228 (CVSS score: 10.0) concerns a critical security vulnerability in the popular Log4j logging library that, if successfully exploited, could lead to remote execution of arbitrary code on compromised systems.  The ease of the exploitation coupled with the widespread use of Log4j library has created a vast pool of targets, even as the shortcoming has attracted swarms of bad actors, who have seized on the opportunity to stage a dizzying array of attacks since its public disclosure last month.  While Microsoft previously pointed out APT35's efforts to acquire and modify the Log4j exploit, the latest findings show that the hacking group has operationalized the flaw to distribute the PowerShell implant capable of retrieving next-stage modules and exfiltrating data to a command-and-control (C2) server.  Log4j Vulnerability CharmPower's modules also support a variety of intelligence gathering functionality, including features to gather system information, list installed applications, take screenshots, enumerate running processes, execute commands sent from the C2 server, and clean up any signs of evidence created by these components.  Cybersecurity The disclosure comes as Microsoft and the NHS cautioned that internet-facing systems running VMware Horizon are being targeted to deploy web shells and a new strain of ransomware called NightSky, with the tech giant connecting the latter to a China-based operator dubbed DEV-0401, which has also deployed LockFile, AtomSilo, and Rook ransomware in the past.  What's more, Hafnium, another threat actor group operating out of China, has also been observed utilizing the vulnerability to attack virtualization infrastructure to extend their typical targeting, Microsoft noted.  \"Judging by their ability to take advantage of the Log4j vulnerability and by the code pieces of the CharmPower backdoor, the actors are able to change gears rapidly and actively develop different implementations for each stage of their attacks,\" the researchers said.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  An Iranian state-sponsored actor has been observed scanning and attempting to abuse the Log4Shell flaw in publicly-exposed Java applications to deploy a hitherto undocumented PowerShell-based modular backdoor dubbed \"CharmPower\" for follow-on post-exploitation.\n",
      "Predicted Label: T1585\n",
      "Sentence: \"The actor's attack setup was obviously rushed, as they used the basic open-source tool for the exploitation and based their operations on previous infrastructure, which made the attack easier to detect and attribute,\" researchers from Check Point said in a report published this week.\n",
      "Predicted Label: T1546.007\n",
      "Sentence: The Israeli cybersecurity company linked the attack to a group known as APT35, which is also tracked using the codenames Charming Kitten, Phosphorus, and TA453, citing overlaps with toolsets previously identified as infrastructure used by the threat actor.\n",
      "Predicted Label: T1552.001\n",
      "Sentence: Cybersecurity Log4Shell aka CVE-2021-44228 (CVSS score: 10.0) concerns a critical security vulnerability in the popular Log4j logging library that, if successfully exploited, could lead to remote execution of arbitrary code on compromised systems.\n",
      "Predicted Label: T1222\n",
      "Sentence: The ease of the exploitation coupled with the widespread use of Log4j library has created a vast pool of targets, even as the shortcoming has attracted swarms of bad actors, who have seized on the opportunity to stage a dizzying array of attacks since its public disclosure last month.\n",
      "Predicted Label: T1059.003\n",
      "Sentence: While Microsoft previously pointed out APT35's efforts to acquire and modify the Log4j exploit, the latest findings show that the hacking group has operationalized the flaw to distribute the PowerShell implant capable of retrieving next-stage modules and exfiltrating data to a command-and-control (C2) server.\n",
      "Predicted Label: T1556\n",
      "Sentence: Log4j Vulnerability CharmPower's modules also support a variety of intelligence gathering functionality, including features to gather system information, list installed applications, take screenshots, enumerate running processes, execute commands sent from the C2 server, and clean up any signs of evidence created by these components.\n",
      "Predicted Label: T1098.003\n",
      "Sentence: Cybersecurity The disclosure comes as Microsoft and the NHS cautioned that internet-facing systems running VMware Horizon are being targeted to deploy web shells and a new strain of ransomware called NightSky, with the tech giant connecting the latter to a China-based operator dubbed DEV-0401, which has also deployed LockFile, AtomSilo, and Rook ransomware in the past.\n",
      "Predicted Label: T1222\n",
      "Sentence: What's more, Hafnium, another threat actor group operating out of China, has also been observed utilizing the vulnerability to attack virtualization infrastructure to extend their typical targeting, Microsoft noted.\n",
      "Predicted Label: T1134.005\n",
      "Sentence: \"Judging by their ability to take advantage of the Log4j vulnerability and by the code pieces of the CharmPower backdoor, the actors are able to change gears rapidly and actively develop different implementations for each stage of their attacks,\" the researchers said.\n",
      "Predicted Label: T1098.003\n"
     ]
    }
   ],
   "source": [
    "# Sample input text\n",
    "text = input(\"Enter text to classify: \")\n",
    "\n",
    "# Call the predict_single function\n",
    "sentence_predictions = predict_single(text, model, tokenizer, context_map, label_map_rev, device)\n",
    "\n",
    "# Print the results\n",
    "for sentence, pred_label, probs_percent in sentence_predictions:\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Label: {pred_label}\")\n",
    "    # print(f\"Confidence Scores: {probs_percent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73547133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
