{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c11426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch, torchtext\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random, math, time\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f36479-9960-4e36-94ec-0c77981bbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121 0.18.0+cpu 4.49.0\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import torch, torchtext, transformers\n",
    "import numpy\n",
    "print(torch.__version__, torchtext.__version__, transformers.__version__)\n",
    "print(numpy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2cacb7-5932-43d6-a62b-367e9944ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/frankaging/Quasi-Attention-ABSA/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc07e1c-8a34-4c91-beb0-1349b64e535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "# .select(range(10000))\n",
    "train_data = load_from_disk(\"tokenized_data_edit/train\")\n",
    "val_data = load_from_disk(\"tokenized_data_edit/validation\")\n",
    "test_data = load_from_disk(\"tokenized_data_edit/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617249f8-95d7-424c-9907-1f159afee61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.rename_column(\"label\", \"labels\")\n",
    "val_data = val_data.rename_column(\"label\", \"labels\")\n",
    "test_data = test_data.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0633e8-36b7-43bd-b520-3f2bf36ac504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text1', 'entity', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 452057\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d437e99e-f2f3-43a8-96ac-6e0a6c64639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"dataset_edit/dataset_edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307ff933-9d37-4dac-bb3c-2d699bca70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # dataset['test'] = dataset['test'].select(range(1000))\n",
    "\n",
    " # test_data = test_data.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd4d17d-f56c-4fad-8dda-ace3b8fdae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text1': 'These Microsoft Office templates are hosted on a command and control server and the downloaded link is embedded in the first stage malicious document', 'entity': 'I-TOOL', 'labels': 'T1584.004', 'input_ids': [2, 455, 755, 1899, 8818, 226, 4700, 158, 43, 979, 137, 656, 629, 137, 114, 3633, 695, 146, 3718, 120, 114, 773, 3872, 815, 1355, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels (MITRE techniques) from both train and validation datasets\n",
    "labels = list(set(dataset['train']['label']).union(set(dataset['validation']['label'])))  # Extract unique labels\n",
    "label_map = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Function to encode labels into integers\n",
    "# def encode_labels(examples):\n",
    "#     # Safely map the labels, providing a default value if a label is not found in the label_map\n",
    "#     examples['labels'] = [label_map.get(label, -1) for label in examples['labels']]\n",
    "    \n",
    "#     return examples\n",
    "\n",
    "# # Apply label encoding\n",
    "# train_data = train_data.map(encode_labels, batched=True)\n",
    "# val_data = val_data.map(encode_labels, batched=True)\n",
    "\n",
    "# # Print an example to verify\n",
    "print(train_data[3])  # It should show tokenized input along with the encoded label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d948d17f-308d-48d9-b49b-4a9702c64c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text1': 'The spear phishing emails contained three attachments in total, each of which exploited an older vulnerability in Microsoft Office (CVE-2012-0158', 'entity': 'B-ACT', 'labels': 'T1203', 'input_ids': [2, 114, 5525, 1587, 2596, 3898, 1775, 4905, 120, 2683, 16, 1041, 135, 388, 2543, 124, 4767, 525, 120, 755, 1899, 12, 539, 17, 2092, 17, 28500, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Make sure each 'entity' is treated as a full string, not split into characters\n",
    "unique_aspects = list(set(aspects for aspects in dataset['train']['entity']))\n",
    "context_map = {asp: i+1 for i, asp in enumerate(unique_aspects)}  # +1 to reserve 0 for padding\n",
    "\n",
    "# # Update encoding accordingly\n",
    "# def encode_context(examples):\n",
    "#     examples[\"context_ids\"] = [\n",
    "#         [context_map[a] for a in aspects if a in context_map] if isinstance(aspects, list) else [context_map.get(aspects, 0)]\n",
    "#         for aspects in examples[\"entity\"]\n",
    "#     ]\n",
    "#     return examples\n",
    "\n",
    "# # Apply context encoding\n",
    "# # train_data = train_data.map(encode_context, batched=True)\n",
    "# # val_data = val_data.map(encode_context, batched=True)\n",
    "# test_data = test_data.map(encode_context, batched=True)\n",
    "\n",
    "# Print an example to verify\n",
    "print(test_data[3])  # It should show tokenized input along with the encoded label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46472511-7c2c-4a11-8876-82951de03ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TTPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, label_key='labels', max_context_id=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.label_key = label_key\n",
    "        self.max_context_id = max_context_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        context_ids = torch.tensor(item[\"context_ids\"], dtype=torch.long)\n",
    "\n",
    "        if self.max_context_id is not None:\n",
    "            context_ids = torch.clamp(context_ids, min=0, max=self.max_context_id)\n",
    "\n",
    "        label = item[self.label_key]\n",
    "        if label == -1:\n",
    "            # Replace -1 with a default class, like 0\n",
    "            label = 0  # or skip the example entirely\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(item[\"input_ids\"]),\n",
    "            \"token_type_ids\": torch.tensor(item[\"token_type_ids\"]),\n",
    "            \"attention_mask\": torch.tensor(item[\"attention_mask\"]),\n",
    "            \"labels\": torch.tensor(item[self.label_key]),\n",
    "            \"context_ids\": context_ids\n",
    "        }\n",
    "\n",
    "train_dataset = TTPDataset(train_data)\n",
    "val_dataset = TTPDataset(val_data)\n",
    "test_dataset = TTPDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e996ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds, label = p\n",
    "    # If using softmax, we need to use argmax to get the final class prediction\n",
    "    preds = preds.argmax(axis=-1)\n",
    "    \n",
    "    # Calculate precision, recall, F1-score, and accuracy\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(label, preds, average='weighted')\n",
    "    accuracy = accuracy_score(label, preds)\n",
    "    \n",
    "    # Return the metrics as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbed29e9-a44d-4448-9c99-d2d937a493b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QACGBertForSequenceClassification(\n",
       "  (bert): ContextBertModel(\n",
       "    (embeddings): BERTEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BERTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ContextBERTEncoder(\n",
       "      (context_layer): ModuleList(\n",
       "        (0-11): 12 x Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ContextBERTLayer(\n",
       "          (attention): ContextBERTAttention(\n",
       "            (self): ContextBERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): ContextBERTPooler(\n",
       "      (attention_gate): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (context_embeddings): Embedding(34, 768)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=505, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/full_model_edit.pth')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f90d34ae-e5c0-4875-84e7-23f16c9e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('real_news_maps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d8e94a-9658-4e9b-a653-4fa13386dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>maps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cybersecurity researchers have detailed the ac...</td>\n",
       "      <td>['T1190','T1078','T1059','T1133','T1078','T102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Korea-linked threat actors behind the Co...</td>\n",
       "      <td>['T1589','T1591','T1598','T1585','T1586','T158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Threat actors are likely exploiting a new vuln...</td>\n",
       "      <td>['T1190','T1059.004','T1505.003','T1548','T107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When we talk about identity in cybersecurity, ...</td>\n",
       "      <td>['T1552.001','T1552.002','T1083','T1119','T109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At least six organizations in South Korea have...</td>\n",
       "      <td>['T1189','T1583.001','T1190','T1059.001','T154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cybersecurity researchers have demonstrated a ...</td>\n",
       "      <td>['T1211','T1059.004','T1071.001','T1003','T1021']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The threat actors behind the Darcula phishing-...</td>\n",
       "      <td>['T1566.001','T1078','T1119','T1071.001','T102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Multiple threat activity clusters with ties to...</td>\n",
       "      <td>['T1566.002','T1189','T1078.004','T1078','T154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Iran-nexus threat actor known as UNC2428 h...</td>\n",
       "      <td>['T1566.001','T1059.003','T1547.001','T1548.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cybersecurity researchers have revealed that R...</td>\n",
       "      <td>['T1475','T1543.003','T1547','T1068','T1036.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  Cybersecurity researchers have detailed the ac...   \n",
       "1  North Korea-linked threat actors behind the Co...   \n",
       "2  Threat actors are likely exploiting a new vuln...   \n",
       "3  When we talk about identity in cybersecurity, ...   \n",
       "4  At least six organizations in South Korea have...   \n",
       "5  Cybersecurity researchers have demonstrated a ...   \n",
       "6  The threat actors behind the Darcula phishing-...   \n",
       "7  Multiple threat activity clusters with ties to...   \n",
       "8  The Iran-nexus threat actor known as UNC2428 h...   \n",
       "9  Cybersecurity researchers have revealed that R...   \n",
       "\n",
       "                                                maps  \n",
       "0  ['T1190','T1078','T1059','T1133','T1078','T102...  \n",
       "1  ['T1589','T1591','T1598','T1585','T1586','T158...  \n",
       "2  ['T1190','T1059.004','T1505.003','T1548','T107...  \n",
       "3  ['T1552.001','T1552.002','T1083','T1119','T109...  \n",
       "4  ['T1189','T1583.001','T1190','T1059.001','T154...  \n",
       "5  ['T1211','T1059.004','T1071.001','T1003','T1021']  \n",
       "6  ['T1566.001','T1078','T1119','T1071.001','T102...  \n",
       "7  ['T1566.002','T1189','T1078.004','T1078','T154...  \n",
       "8  ['T1566.001','T1059.003','T1547.001','T1548.00...  \n",
       "9  ['T1475','T1543.003','T1547','T1068','T1036.00...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dab9c1a-55c9-47f9-a480-1e4ec2cf51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "import spacy\n",
    "\n",
    "# Load tokenizer and spaCy model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ibm-research/CTI-BERT\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Inverse label map\n",
    "label_map_rev = {v: k for k, v in label_map.items()}\n",
    "\n",
    "def predict_single(text, model, tokenizer, context_map, label_map_rev, device, max_len=64):\n",
    "    # 1. Tokenize input\n",
    "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
    "\n",
    "    seq_len = input_ids.size(1)\n",
    "\n",
    "    # 2. Extract entities using spaCy for context\n",
    "    doc = nlp(text)\n",
    "    aspects = list(set([ent.text for ent in doc.ents if ent.text in context_map]))\n",
    "\n",
    "\n",
    "    # 3. Encode context\n",
    "    context_ids = [context_map.get(a, 0) for a in aspects]\n",
    "    if not context_ids:\n",
    "        context_ids = [0]  # default to padding if no valid entity\n",
    "    context_ids = torch.tensor([context_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    # 4. Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            seq_lens=[seq_len],\n",
    "            context_ids=context_ids,\n",
    "        )\n",
    "\n",
    "    logits = outputs\n",
    "    probs = F.softmax(logits, dim=1).squeeze()\n",
    "    pred_idx = torch.argmax(probs).item()\n",
    "    pred_label = label_map_rev[pred_idx]\n",
    "\n",
    "    return pred_label, probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a6a693-20ae-443c-866c-c5a0e1adf813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# input_text = input(\"Enter text to classify: \")\n",
    "# predicted_label, confidence_scores = predict_single(input_text, model, tokenizer, context_map, label_map_rev, device)\n",
    "\n",
    "# print(f\"\\nPredicted Label: {predicted_label}\")\n",
    "# print(\"\\nTop 5 Confidence Scores:\")\n",
    "\n",
    "# # Get indices of top 5 scores\n",
    "# top_indices = np.argsort(confidence_scores)[-5:][::-1]\n",
    "\n",
    "# for idx in top_indices:\n",
    "#     label = label_map_rev[idx]\n",
    "#     score = confidence_scores[idx]\n",
    "#     print(f\"{label}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1d7fbe-0824-484e-b5b7-0d5a013d0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "import spacy\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Load tokenizer and spaCy model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"ibm-research/CTI-BERT\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Inverse label map\n",
    "label_map_rev = {v: k for k, v in label_map.items()}\n",
    "label_map = {label: idx for idx, label in label_map_rev.items()}\n",
    "  # forward mapping, important for later\n",
    "\n",
    "def predict_single(text, model, tokenizer, context_map, device, max_len=64):\n",
    "    # 1. Tokenize input\n",
    "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
    "\n",
    "    seq_len = input_ids.size(1)\n",
    "\n",
    "    # 2. Extract entities using spaCy for context\n",
    "    doc = nlp(text)\n",
    "    aspects = list(set([ent.text for ent in doc.ents if ent.text in context_map]))\n",
    "\n",
    "    # 3. Encode context\n",
    "    context_ids = [context_map.get(a, 0) for a in aspects]\n",
    "    if not context_ids:\n",
    "        context_ids = [0]  # default to padding if no valid entity\n",
    "    context_ids = torch.tensor([context_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    # 4. Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            seq_lens=[seq_len],\n",
    "            context_ids=context_ids,\n",
    "        )\n",
    "\n",
    "    logits = outputs\n",
    "    probs = F.softmax(logits, dim=1).squeeze()\n",
    "\n",
    "    return probs.cpu().numpy()  # Now return **only** probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d81aec3a-f3b8-41ad-a34d-03175f910c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndcg_for_sample(probs, true_labels, label_map, k=5):\n",
    "    \"\"\"\n",
    "    probs: np.array of shape (num_classes,)\n",
    "    true_labels: list of correct labels, ex: ['T1190', 'T1078', ...]\n",
    "    label_map: dict mapping label text to indices\n",
    "    k: cutoff for NDCG@k\n",
    "    \"\"\"\n",
    "    # Step 1: Build true relevance vector\n",
    "    num_classes = probs.shape[0]\n",
    "    true_relevance = [0] * num_classes\n",
    "    for label in true_labels:\n",
    "        idx = label_map.get(label)\n",
    "        if idx is not None:\n",
    "            true_relevance[idx] = 1  # relevant\n",
    "\n",
    "    true_relevance = [true_relevance]  # sklearn expects 2D array\n",
    "    probs = [probs.tolist()]           # sklearn expects 2D array\n",
    "\n",
    "    return ndcg_score(true_relevance, probs, k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "904f7c2a-2375-4d2d-b122-af031fe94612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_ndcg_for_sample(probs, true_labels, label_map,relevant_list, k=5):\n",
    "#     \"\"\"\n",
    "#     probs: np.array of shape (num_classes,)\n",
    "#     true_labels: list of correct labels, ex: ['T1190', 'T1078', ...]\n",
    "#     label_map: dict mapping label text to indices\n",
    "#     k: cutoff for NDCG@k\n",
    "#     \"\"\"\n",
    "#     # Step 1: Build true relevance vector\n",
    "#     # num_classes = probs.shape[0]\n",
    "#     # true_relevance = [1] * 5\n",
    "#     true_relevance = []\n",
    "#     score = 0\n",
    "#     for x in true_labels[-5:]:\n",
    "#         if x in relevant_list:\n",
    "#             score = score + 1\n",
    "    \n",
    "#     # for label in true_labels[-5:]:\n",
    "#     #     # print(label)\n",
    "#     #     idx = label_map.get(label)\n",
    "#     #     # print(idx)\n",
    "#     #     if idx is not None:\n",
    "#     #         true_relevance.append(1)  # relevant\n",
    "\n",
    "#     # # true_relevance = [true_relevance]  # sklearn expects 2D array\n",
    "#     # # probs = [probs.tolist()]           # sklearn expects 2D array\n",
    "\n",
    "#     # # print('tru value',true_relevance)\n",
    "#     print('predict value',relevant_list,'+',score)\n",
    "    \n",
    "#     return (score/5),score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56d1cec-109c-4fa5-8b03-589317129eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b7125-4a94-4c70-92e4-242c877b134a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "934e6680-bc88-45a7-aa13-ca931a860f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict value ['T1048', 'T1562', 'T1583.006', 'T1569.002', 'T1037.004', 'T1078.002', 'T1087.002', 'T1037.002', 'T1593', 'T1222.002', 'T1092', 'T1008', 'T1590.001', 'T1072', 'T1498', 'T1098.001', 'T1037.001', 'T1070.006', 'T1070.001', 'T1027.005'] + 0\n",
      "true value ['T1190', 'T1078', 'T1059', 'T1133', 'T1078', 'T1027']\n",
      "Sample 0: NDCG@5 = 0.0000\n",
      "predict value ['T1621', 'T1136.001', 'T1218.010', 'T1218.005', 'T1037.001', 'T1564.006', 'T1543', 'T1070.003', 'T1005', 'T1606.002', 'T1550.002', 'T1560.001', 'T1104', 'T1583.006', 'T1590', 'T1555.005', 'T1071', 'T1092', 'T1585', 'T1134.003'] + 0\n",
      "true value ['T1589', 'T1591', 'T1598', 'T1585', 'T1586', 'T1587']\n",
      "Sample 1: NDCG@5 = 0.0000\n",
      "predict value ['T1222.002', 'T1569.002', 'T1087.002', 'T1497.001', 'T1072', 'T1092', 'T1590.001', 'T1078.002', 'T1037.001', 'T1048', 'T1037.004', 'T1543', 'T1498', 'T1574.010', 'T1056', 'T1205.001', 'T1608', 'T1037.002', 'T1005', 'T1546.016'] + 1\n",
      "true value ['T1190', 'T1059.004', 'T1505.003', 'T1548', 'T1070', 'T1003']\n",
      "Sample 2: NDCG@5 = 0.2000\n",
      "predict value ['T1056', 'T1087.002', 'T1005', 'T1497.001', 'T1205.001', 'T1574.010', 'T1547', 'T1542.003', 'T1092', 'T1222.002', 'T1585', 'T1111', 'T1583.006', 'T1078.002', 'T1037.001', 'T1569.002', 'T1059.007', 'T1003.004', 'T1550.002', 'T1048'] + 0\n",
      "true value ['T1552.001', 'T1552.002', 'T1083', 'T1119', 'T1098', 'T1078']\n",
      "Sample 3: NDCG@5 = 0.0000\n",
      "predict value ['T1564.006', 'T1555.005', 'T1560.001', 'T1037.001', 'T1218.005', 'T1070.003', 'T1505.003', 'T1608', 'T1583.006', 'T1569.002', 'T1590.001', 'T1027.005', 'T1005', 'T1087.002', 'T1543', 'T1550.002', 'T1048', 'T1547', 'T1564.004', 'T1137.001'] + 0\n",
      "true value ['T1189', 'T1583.001', 'T1190', 'T1059.001', 'T1547.001', 'T1202']\n",
      "Sample 4: NDCG@5 = 0.0000\n",
      "predict value ['T1027.005', 'T1550.002', 'T1217', 'T1543', 'T1010', 'T1621', 'T1570', 'T1018', 'T1568.003', 'T1136.001', 'T1218.010', 'T1056.004', 'T1098.001', 'T1568.001', 'T1564.006', 'T1104', 'T1037.005', 'T1213.001', 'T1037.001', 'T1213.002'] + 0\n",
      "true value ['T1211', 'T1059.004', 'T1071.001', 'T1003', 'T1021']\n",
      "Sample 5: NDCG@5 = 0.0000\n",
      "predict value ['T1005', 'T1087.002', 'T1497.001', 'T1569.002', 'T1543', 'T1205.001', 'T1056', 'T1585', 'T1037.001', 'T1003.004', 'T1048', 'T1222.002', 'T1608', 'T1037.002', 'T1059.007', 'T1583.006', 'T1574.010', 'T1547', 'T1542.003', 'T1137.001'] + 0\n",
      "true value ['T1566.001', 'T1078', 'T1119', 'T1071.001', 'T1027', 'T1499']\n",
      "Sample 6: NDCG@5 = 0.0000\n",
      "predict value ['T1048', 'T1092', 'T1583.006', 'T1037.004', 'T1070.001', 'T1560.001', 'T1590.001', 'T1218.005', 'T1562', 'T1070.003', 'T1555.003', 'T1072', 'T1606.002', 'T1569.002', 'T1498', 'T1555.005', 'T1114.001', 'T1037.001', 'T1137.002', 'T1222.002'] + 0\n",
      "true value ['T1566.002', 'T1189', 'T1078.004', 'T1078', 'T1548', 'T1036']\n",
      "Sample 7: NDCG@5 = 0.0000\n",
      "predict value ['T1560.001', 'T1082', 'T1003.004', 'T1037.004', 'T1583.006', 'T1555.005', 'T1497.001', 'T1564.006', 'T1569.002', 'T1574.010', 'T1037.001', 'T1562', 'T1092', 'T1070.003', 'T1087.002', 'T1218.005', 'T1136.001', 'T1205.001', 'T1606.002', 'T1564.004'] + 0\n",
      "true value ['T1566.001', 'T1059.003', 'T1547.001', 'T1548.002', 'T1036.005', 'T1110.001']\n",
      "Sample 8: NDCG@5 = 0.0000\n",
      "predict value ['T1010', 'T1568.003', 'T1550.002', 'T1092', 'T1543', 'T1098.001', 'T1497.001', 'T1037.002', 'T1005', 'T1542.003', 'T1104', 'T1212', 'T1564.004', 'T1606.002', 'T1021.006', 'T1072', 'T1587.004', 'T1037.005', 'T1056.004', 'T1593'] + 1\n",
      "true value ['T1475', 'T1543.003', 'T1547', 'T1068', 'T1036.003', 'T1557.002']\n",
      "Sample 9: NDCG@5 = 0.2000\n",
      "\n",
      "Mean NDCG@5 over dataset = 0.0400\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Example: load your dataset\n",
    "# data = pd.read_csv(\"real_news_maps.csv\")  # with 'news' and 'maps' columns\n",
    "\n",
    "# all_ndcg_scores = []\n",
    "\n",
    "# for idx, row in data.iterrows():\n",
    "#     text = row['news']\n",
    "#     true_labels = eval(row['maps'])  # careful: safely convert string to list\n",
    "    \n",
    "#     probs = predict_single(text, model, tokenizer, context_map, device)\n",
    "#     top_indices = np.argsort(probs)[-20:][::-1]\n",
    "#     relevant_list = []\n",
    "#     for idx2 in top_indices:\n",
    "#         label = label_map_rev[idx2]\n",
    "#         relevant_list.append(label)\n",
    "#     ndcg,score = compute_ndcg_for_sample(probs, true_labels, label_map,relevant_list)\n",
    "\n",
    "#     print('true value',true_labels[:6])\n",
    "#     # print(score)\n",
    "    \n",
    "#     all_ndcg_scores.append(ndcg)\n",
    "#     print(f\"Sample {idx}: NDCG@5 = {ndcg:.4f}\")\n",
    "\n",
    "# # After all samples\n",
    "# mean_ndcg = sum(all_ndcg_scores) / len(all_ndcg_scores)\n",
    "# print(f\"\\nMean NDCG@5 over dataset = {mean_ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7119c029-abeb-4e11-976e-d4ba12e40158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "    print(label_map_rev.get('T1593.001'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2dd6e79-e7f2-4666-b24c-b519672a6de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: NDCG@5 = 0.0000\n",
      "Sample 1: NDCG@5 = 0.0544\n",
      "Sample 2: NDCG@5 = 0.0544\n",
      "Sample 3: NDCG@5 = 0.0000\n",
      "Sample 4: NDCG@5 = 0.0000\n",
      "Sample 5: NDCG@5 = 0.0000\n",
      "Sample 6: NDCG@5 = 0.0000\n",
      "Sample 7: NDCG@5 = 0.0000\n",
      "Sample 8: NDCG@5 = 0.0000\n",
      "Sample 9: NDCG@5 = 0.0538\n",
      "\n",
      "Mean NDCG@5 over dataset = 0.0163\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: load your dataset\n",
    "data = pd.read_csv(\"real_news_maps.csv\")  # with 'news' and 'maps' columns\n",
    "\n",
    "all_ndcg_scores = []\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    text = row['news']\n",
    "    true_labels = eval(row['maps'])  # careful: safely convert string to list\n",
    "    \n",
    "    probs = predict_single(text, model, tokenizer, context_map, device)\n",
    "    ndcg = compute_ndcg_for_sample(probs, true_labels, label_map,k=20)\n",
    "    \n",
    "    all_ndcg_scores.append(ndcg)\n",
    "    print(f\"Sample {idx}: NDCG@5 = {ndcg:.4f}\")\n",
    "\n",
    "# After all samples\n",
    "mean_ndcg = sum(all_ndcg_scores) / len(all_ndcg_scores)\n",
    "print(f\"\\nMean NDCG@5 over dataset = {mean_ndcg:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
